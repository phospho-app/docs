---
title: "Train AI models"
description: "How to train AI models for robotics applications."
---

phospho dev kit makes it easy to train robotics AI models with LeRobot from Huggingface.

## What is LeRobot?

![LeRobot logo](https://cdn-uploads.huggingface.co/production/uploads/631ce4b244503b72277fc89f/MNkMdnJqyPvOAEg20Mafg.png)

LeRobot is a platform designed to facilitate access to real-world robotics by providing models, datasets, and tools in PyTorch, to make robotics more accessible for everyone.

It focuses on state-of-the-art approaches in imitation learning and reinforcement learning, offering pretrained models, human-collected demonstration datasets, and simulated environments. 

- [LeRobot github](https://github.com/huggingface/lerobot)
- [LeRobot on Huggingface](https://huggingface.co/lerobot)
- [AI models for robotics](https://huggingface.co/models?pipeline_tag=robotics&sort=trending)

## Step by step guide

In this guide, we will use the Phospho Junior Dev Kit to record a dataset and upload it to Hugging Face.  

<Note>Make sure you have already completed the [Installation Guide](/unboxings/dk1).</Note>  

## Prerequisites  

- To automatically upload your dataset, you need a Hugging Face account. If you donâ€™t have one, please create it [here](https://huggingface.co/join).  
- You need a device for training your model. We recommend using a GPU for faster training.  
<Info>The phospho teleo app requires a Meta Quest 2, Pro, 3 or 3s to run</Info>  
- Ensure that your control module is turned on and connected to the robot arm and camera.  

## 1. Set up your Hugging Face token  

1. First, create an access token for your Hugging Face account. Log in to your Hugging Face account, go to your profile, and click **Access Token** in the sidebar.  

2. Select the **Write** option to grant write access to your account. This is necessary for creating new datasets and uploading files. Name your token and click **Create**.  

![Create HF Token](/assets/create-hf-token.png)  

3. Copy the token and save it in a secure place. You will need it later.  

4. Access the control module server at `phosphobot.local:80/admin`, paste the token, and save it.  

![Select Phosphobot server](/assets/hf-admin-page.png)  

## 2. Start teleoperation and recording 

<Info>Make sure you have already completed the [Installation Guide](/unboxings/dk1#5-set-up-your-meta-quest-app) and that you have a [MetaQuest](https://www.meta.com/fr/quest/quest-3/?srsltid=AfmBOorMLUmJKFQr35ssCi1DDqSNgpHk0sLHqo_tHG8kgclCYbMToAPa)</Info>

1. Go to the Meta Quest Store, search for the **Phospho Teleop** application. 

2. Open the application. You should see a screen displaying **Phoshobot** along with the server ping. Click the **Connect** button.  
<Warning>Ensure that you are connected to the same network as the control module.</Warning>  

![Select Phosphobot server](/assets/changeme-unity-server.png)  

3. Upon connecting, you should see the main camera feed if a camera is connected. You can move various assets in the metaverse as needed.  
   - Press the `A` button once to start teleoperation and begin moving your controller.  
   - Press the `A` button again to stop the teleoperation; the robot will stop.  

4. Start recording by pressing the `B` button. You can leave the default settings for your first attempt.  
   - Press the `B` button again to stop the recording.  

5. Continue teleoperating and stop the recording when you're done.  

6. The recording is automatically saved in **LeRobot** format and uploaded to your Hugging Face account. You can check it in your profile.  

## 3. Train your first model  

1. On the device where you want to run the training, install the [Phosphobot package](https://github.com/phospho-app/phosphobot):  

   ```bash
   pip install --upgrade phosphobot
   ```

2. Clone the [LeRobot repository](https://github.com/huggingface/lerobot) and install it:  

   ```bash
   git clone https://github.com/huggingface/lerobot.git
   cd lerobot
   pip install -e .  # Requires Python 3.10+
   ```

3. *(Optional)* If you want to use Weights & Biases for tracking training metrics, log in with:  

   ```bash
   wandb login
   ```

4. Launch the training script with the following command in the `lerobot` repository (change the device to `cuda` if you have an NVIDIA GPU or `cpu` if you donâ€™t have a GPU).  
   Ensure that your `lerobot` virtual environment is activated.  

   ```bash
   sudo python lerobot/scripts/train.py \
     --dataset.repo_id=<HF_USERNAME>/<DATASET_NAME> \
     --policy.type=<act or diffusion or tdmpc or vqbet> \
     --output_dir=outputs/train/phoshobot_test \
     --job_name=phosphobot_test \
     --device=mps \
     --wandb.enable=true
   ```

5. You will find your trained model in `lerobot/outputs/train/`.  

## What's next?  

- Explore the rest of the documentation and try out the [example scripts](/examples).  
- Join [our Discord](https://discord.gg/cbkggY6NSK) and send us a picture of your setup! ðŸ’š  

### Automatic updates  

Every time the control module is powered on, it will check for updates and install them automatically. Updates will be available the next time you power it on.  

### Support  

Weâ€™re constantly rolling out updates to improve your experience, add new features, and fix issues.  

If you encounter any issues, first reboot the control module to ensure it is up to date. *The version ID is displayed on the dashboard.*  

If the issue persists, [reach out to us on our Discord](https://discord.gg/cbkggY6NSK). Our team of engineers is here to help!